<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models | INCaS Research Showcase</title><link>https://incas.example.org/tags/large-language-models/</link><atom:link href="https://incas.example.org/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><description>Large Language Models</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>zh-CN</language><lastBuildDate>Wed, 15 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://incas.example.org/media/icon_hu_982c5d63a71b2961.png</url><title>Large Language Models</title><link>https://incas.example.org/tags/large-language-models/</link></image><item><title>PASO: Step Parallel Stochastic Optimization</title><link>https://incas.example.org/publications/paso/</link><pubDate>Wed, 15 Oct 2025 00:00:00 +0000</pubDate><guid>https://incas.example.org/publications/paso/</guid><description>&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This work reframes autoregressive gradient descent (GD)—including SGD and Adam—as solving a system of triangular nonlinear equations (TNEs).&lt;br&gt;
Solving the TNE system yields a trajectory identical to classical GD but allows step-parallel gradient computation.&lt;br&gt;
Building upon this viewpoint, PASO accelerates optimizers on workloads such as &lt;strong&gt;Llama-3.2-1B&lt;/strong&gt;, cutting gradient steps by &lt;strong&gt;91×&lt;/strong&gt; and wall-clock time by &lt;strong&gt;7.5×&lt;/strong&gt; without hurting quality.&lt;/p&gt;
&lt;h2 id="methodology"&gt;Methodology&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Triangular Nonlinear Equation (TNE) Reformulation&lt;/strong&gt;&lt;br&gt;
The entire SGD/Adam trajectory is rewritten as a coupled TNE system whose solution exactly matches the autoregressive iteration.&lt;br&gt;
This insight lets us decouple temporal dependencies and reason about GD as a global solve.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Parallel Solver for Optimizers&lt;/strong&gt;&lt;br&gt;
By solving the TNE blocks jointly, PASO evaluates gradients for many steps simultaneously, achieving massive step-level parallelism.&lt;br&gt;
The solver is compatible with momentum terms and bias corrections used in SGD/Adam.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Theoretical Guarantees&lt;/strong&gt;&lt;br&gt;
The TNE system has a unique solution; solving it converges to the GD trajectory in equal or fewer iterations.&lt;br&gt;
PASO therefore inherits convergence guarantees of the base optimizer while changing only the execution schedule.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
&lt;figure &gt;
&lt;div class="flex justify-center "&gt;
&lt;div class="w-full" &gt;&lt;img src="https://incas.example.org/images/paso/PASO_v10.png" alt="PASO Overview" loading="lazy" data-zoomable /&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id="experimental-results"&gt;Experimental Results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step Reduction&lt;/strong&gt;: Up to &lt;strong&gt;91×&lt;/strong&gt; fewer GD iterations for the same optimization horizon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wall-Clock Speedup&lt;/strong&gt;: Up to &lt;strong&gt;7.5×&lt;/strong&gt; acceleration on large models such as &lt;em&gt;Llama‑3.2‑1B&lt;/em&gt;, measured end-to-end.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model Quality&lt;/strong&gt;: No measurable drop in perplexity or downstream metrics compared with baselines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Benefits extend to different backbone optimizers (SGD, Adam, AdamW) and both vision/NLP workloads.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="step-block-size-vs-final-quality"&gt;Step Block Size vs. Final Quality&lt;/h3&gt;
&lt;p&gt;
&lt;figure &gt;
&lt;div class="flex justify-center "&gt;
&lt;div class="w-full" &gt;&lt;img src="https://incas.example.org/images/paso/CIIFAR10_PandIter.png" alt="Window Size Ablation" loading="lazy" data-zoomable /&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Larger PASO windows shrink the required iterations (down to 5k at \(p=19\)) while
keeping CIFAR-10 accuracy within 1% of the serial baseline. This serves as our primary
“step block size vs. quality” visualization.&lt;/p&gt;
&lt;h3 id="solver-precision-vs-convergence-stability"&gt;Solver Precision vs. Convergence Stability&lt;/h3&gt;
&lt;p&gt;
&lt;figure &gt;
&lt;div class="flex justify-center "&gt;
&lt;div class="w-full" &gt;&lt;img src="https://incas.example.org/images/paso/EMA&amp;amp;Tol_Acc_Pre_Rec_F1_Itr_v4.png" alt="Tolerance vs. Metrics" loading="lazy" data-zoomable /&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Tightening the PASO tolerance (and EMA decay) stabilizes precision/recall/F1 while
slightly increasing iterations. This figure highlights the trade-off between solver
accuracy and wall-clock cost.&lt;/p&gt;
&lt;h3 id="hardware-utilization--parallel-efficiency"&gt;Hardware Utilization &amp;amp; Parallel Efficiency&lt;/h3&gt;
&lt;p&gt;
&lt;figure &gt;
&lt;div class="flex justify-center "&gt;
&lt;div class="w-full" &gt;&lt;img src="https://incas.example.org/images/paso/Speedup_Ratio.png" alt="Cost Ratio vs. Window Size" loading="lazy" data-zoomable /&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The measured cost ratio \(m = pK/T\) remains ≈1 even as PASO increases the window size,
showing that parallel step blocks don’t inflate total gradient FLOPs—i.e., GPUs/TPUs stay
busy without extra overhead. Replace this with an actual utilization plot once you have
profiling traces.&lt;/p&gt;</description></item></channel></rss>